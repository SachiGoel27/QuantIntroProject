{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **GTSF IC Quant Mentorship**\n",
        "### **Python for Quantitative Finance Fundamentals**\n",
        "\n",
        "**Name:** Sachi Goel\n",
        "**GT Username:** sgoel304\n",
        "**Due Date:** October 7, 2025  \n",
        "\n",
        "---\n",
        "\n",
        "## **Project Overview**\n",
        "\n",
        "This project will test your understanding of the fundamental concepts covered in our first four weeks: probability/statistics, time value of money, basic portfolio theory, and financial data analysis using Python.\n",
        "\n",
        "### **What You'll Demonstrate**\n",
        "- **Data Handling**: Download, clean, and analyze real financial data\n",
        "- **Statistical Analysis**: Calculate returns, risk metrics, and correlations  \n",
        "- **Portfolio Basics**: Apply diversification and risk-return concepts\n",
        "- **Python Skills**: Use pandas, numpy, and matplotlib effectively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Setup and Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# You may only use these libraries (same as original project)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "# You may only use these libraries (same as original project)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import yfinance as yf\n",
        "\n",
        "# Configuration\n",
        "pd.set_option('display.max_columns', 10)\n",
        "pd.set_option('display.precision', 4)\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"âœ… Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 1: Data Collection & Basic Analysis (25 points)**\n",
        "\n",
        "### **Step 1.1: Download Stock Data**\n",
        "Download 3 years of data (2021-2024) for these assets and create clean datasets:\n",
        "\n",
        "**Required Assets:**\n",
        "- **AAPL** (Apple) - Large tech stock\n",
        "- **JNJ** (Johnson & Johnson) - Defensive stock  \n",
        "- **SPY** (S&P 500 ETF) - Market benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_stock_data(tickers, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Download adjusted close prices for multiple stocks.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    tickers : list\n",
        "        List of stock symbols\n",
        "    start_date : str  \n",
        "        Start date as 'YYYY-MM-DD'\n",
        "    end_date : str\n",
        "        End date as 'YYYY-MM-DD'\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with dates as index, stocks as columns\n",
        "    \"\"\"\n",
        "    data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=True)['Close']\n",
        "    # remove duplicates\n",
        "    data = data[~data.index.duplicated(keep='last')]\n",
        "    # back fill\n",
        "    data = data.bfill()\n",
        "    # forward fill\n",
        "    data = data.ffill()\n",
        "    return data\n",
        "\n",
        "# Download the data\n",
        "tickers = ['AAPL', 'JNJ', 'SPY'] \n",
        "prices_df = download_stock_data(tickers, '2021-01-01', '2024-01-01')\n",
        "\n",
        "# Display first few rows and basic info\n",
        "print(\"First 5 rows:\")\n",
        "print(prices_df.head())\n",
        "print(f\"\\nDataset shape: {prices_df.shape}\")\n",
        "print(f\"Date range: {prices_df.index[0].date()} to {prices_df.index[-1].date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 1.2: Calculate Returns**\n",
        "Calculate both simple and log returns as covered in the slides:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_returns(prices_df):\n",
        "    \"\"\"\n",
        "    Calculate simple and log returns from price data.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (simple_returns_df, log_returns_df)\n",
        "    \"\"\"\n",
        "    simpledf = prices_df.pct_change()\n",
        "    longdf = np.log(prices_df).diff()\n",
        "    return (simpledf, longdf)\n",
        "\n",
        "# Calculate returns\n",
        "simple_returns, log_returns = calculate_returns(prices_df)\n",
        "\n",
        "print(\"Simple returns - first 5 rows:\")\n",
        "print(simple_returns.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions - Part 1**\n",
        "**Answer these questions in the markdown cell below:**\n",
        "\n",
        "1. How many trading days of data do you have for each stock?\n",
        "2. What's the difference between the largest simple return and largest log return for AAPL?\n",
        "3. Why do we typically use adjusted close prices instead of regular close prices?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Your Answers - Part 1:**\n",
        "\n",
        "1. The number of trading days of data for each stock would the number of rows I have in my prices_df dataset. In this case, we have 753 days of data.\n",
        "\n",
        "2. The largest simple return for APPL is 0.08897490774924677 and the largest log return is 0.08523680213278872 (obtained using simple_returns['AAPL'].max(), log_returns['AAPL'].max() respectively). The difference of these values is 0.08897490774924677 - 0.08523680213278872 = 0.00373810561646.\n",
        "\n",
        "3. If we just looked at the normal close price, it wouldn't take into account certain corporate actions that affect the stock price, like stock splits or cash dividends which would affect the price of the stock and isn't an accurate representation of the security's true value. Without using the adjusted price, a stock split would appear as a huge, permanent drop in value on a price chart, and calculations of returns would ignore the cash value delivered by dividends, leading to an understatement of total long-term returns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 2: Risk and Return Analysis (25 points)**\n",
        "\n",
        "### **Step 2.1: Basic Statistics**\n",
        "Calculate the key statistics we covered in class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_basic_statistics(returns_df):\n",
        "    \"\"\"\n",
        "    Calculate mean, standard deviation, and annualized metrics.\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        Table with statistics for each stock\n",
        "    \"\"\"\n",
        "    stats_dict = {}\n",
        "    \n",
        "    for stock in returns_df.columns:\n",
        "\n",
        "        ######################\n",
        "        # YOUR CODE HERE\n",
        "        # Calculate:\n",
        "        # - Daily mean return\n",
        "        # - Daily standard deviation  \n",
        "        # - Annualized return (daily_mean * 252)\n",
        "        # - Annualized volatility (daily_std * sqrt(252))\n",
        "        # - Sharpe ratio (assume 2% risk-free rate)\n",
        "        ######################\n",
        "        daily_returns = returns_df[stock]\n",
        "        daily_mean = daily_returns.mean()\n",
        "        daily_std = daily_returns.std()\n",
        "        annual_return = daily_mean * 252\n",
        "        annual_volatility = daily_std * np.sqrt(252)\n",
        "        sharpe_ratio = (annual_return - .02) / annual_volatility\n",
        "\n",
        "        stats_dict[stock] = {\n",
        "            'Daily Mean Return': daily_mean,\n",
        "            'Daily Std Dev': daily_std,\n",
        "            'Annualized Return': annual_return,\n",
        "            'Annualized Volatility': annual_volatility,\n",
        "            'Sharpe Ratio': sharpe_ratio\n",
        "        }\n",
        "\n",
        "    \n",
        "    return pd.DataFrame(stats_dict).T\n",
        "\n",
        "# Calculate and display statistics\n",
        "stats_table = calculate_basic_statistics(simple_returns)\n",
        "print(\"Return and Risk Statistics:\")\n",
        "print(stats_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 2.2: Risk-Return Visualization** \n",
        "Create the classic risk-return scatter plot from the slides:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_risk_return(stats_df):\n",
        "    \"\"\"\n",
        "    Create a risk-return scatter plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    ######################\n",
        "    # YOUR CODE HERE  \n",
        "    # Create scatter plot with:\n",
        "    # - x-axis: Annualized Volatility\n",
        "    # - y-axis: Annualized Return\n",
        "    # - Label each point with stock symbol\n",
        "    # - Add proper title and axis labels\n",
        "    ######################\n",
        "    plt.scatter(\n",
        "        stats_df['Annualized Volatility'], \n",
        "        stats_df['Annualized Return'],\n",
        "        c=stats_df['Sharpe Ratio'],  \n",
        "        cmap='viridis',              \n",
        "        s=100,                      \n",
        "        edgecolors='k'\n",
        "    )\n",
        "\n",
        "    for i, txt in enumerate(stats_df.index):\n",
        "        plt.annotate(\n",
        "            txt, \n",
        "            (stats_df['Annualized Volatility'][i] + 0.005, stats_df['Annualized Return'][i]),\n",
        "            fontsize=10,\n",
        "            weight='bold'\n",
        "        )\n",
        "\n",
        "    plt.title('Risk-Return Profile of Assets', fontsize=16)\n",
        "    plt.xlabel('Annualized Volatility (Risk)', fontsize=12)\n",
        "    plt.ylabel('Annualized Return', fontsize=12)\n",
        "\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.set_label('Sharpe Ratio', rotation=270, labelpad=15)\n",
        "\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.axhline(0, color='gray', linestyle='-', linewidth=0.5)\n",
        "    plt.show()\n",
        "\n",
        "plot_risk_return(stats_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions - Part 2**\n",
        "\n",
        "4. Which stock has the highest Sharpe ratio? What does this mean?\n",
        "5. Does the risk-return relationship match what you'd expect from the slides?\n",
        "6. How does SPY compare to the individual stocks in terms of risk?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Your Answers - Part 2:**\n",
        "\n",
        "4. The stock with the highest Sharpe ratio was AAPL. A Sharpe ratio compares an investment's return with its risk, since AAPL had a high ratio that means it has a higher excess return as compared to the risk an investor has to take, as compared to the other stocks. AAPL has a more attractive risk-adjusted return.\n",
        "\n",
        "5. Yes it makes sense. For AAPL it had the highest risk of .2780 annualized volatility and devliered the highest return .1776. Similar with JNJ it had the lowest risk of .1619 and the lowest return of .0406. Since riskier assests provide more opportunity for higher returns, these values make sense.\n",
        "\n",
        "6. SPY is signifcantly less risky than AAPL, which is expected since SPY is an ETF while AAPL is one stock. However, it appears that SPY is slightly more risky than JNJ (determined by the annualized volatility), but this can also be explained since JNJ is a blue-chip stock with stable earnings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 3: Correlation and Diversification (25 points)**\n",
        "\n",
        "### **Step 3.1: Correlation Analysis**\n",
        "Calculate and analyze correlations as discussed in portfolio theory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_correlations(returns_df):\n",
        "    \"\"\"\n",
        "    Calculate correlation matrix and analyze diversification benefits.\n",
        "    \"\"\"\n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = returns_df.corr()\n",
        "    \n",
        "    print(\"Correlation Matrix:\")\n",
        "    print(corr_matrix)\n",
        "    \n",
        "    # Create correlation heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Create a heatmap of the correlation matrix\n",
        "    # Hint: You can use plt.imshow() with a colormap\n",
        "    # Add colorbar and proper labels\n",
        "    ######################\n",
        "\n",
        "    plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest') \n",
        "    plt.colorbar()\n",
        "\n",
        "    labels = corr_matrix.columns\n",
        "    n_assets = len(labels)\n",
        "    plt.xticks(np.arange(n_assets), labels, rotation=45)\n",
        "    plt.yticks(np.arange(n_assets), labels)\n",
        "\n",
        "    for i in range(n_assets):\n",
        "        for j in range(n_assets):\n",
        "            text = plt.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
        "                           ha=\"center\", va=\"center\", color=\"black\" if abs(corr_matrix.iloc[i, j]) < 0.8 else \"white\")\n",
        "    \n",
        "    plt.title('Asset Correlation Heatmap', fontsize=16)\n",
        "    plt.show()\n",
        "    \n",
        "    return corr_matrix\n",
        "\n",
        "correlation_matrix = analyze_correlations(simple_returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 3.2: Portfolio Construction**\n",
        "Build a simple equal-weighted portfolio and analyze its performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_equal_weighted_portfolio(returns_df):\n",
        "    \"\"\"\n",
        "    Create an equal-weighted portfolio of AAPL and JNJ.\n",
        "    (Exclude SPY since it's our benchmark)\n",
        "    \"\"\"\n",
        "    # Create equal-weighted portfolio of individual stocks\n",
        "    portfolio_returns = returns_df[['AAPL', 'JNJ']].mean(axis=1)\n",
        "    \n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Calculate portfolio statistics:\n",
        "    # - Mean return (annualized)  \n",
        "    # - Standard deviation (annualized)\n",
        "    # - Sharpe ratio\n",
        "    ######################\n",
        "\n",
        "    # port_mean = portfolio_returns.mean() * 252\n",
        "    # port_std = portfolio_returns.std() * np.sqrt(252)\n",
        "\n",
        "    # port_sharpe = (port_mean - .02) / port_std\n",
        "    \n",
        "    return portfolio_returns\n",
        "\n",
        "# Create portfolio and compare to individual stocks\n",
        "portfolio_rets = create_equal_weighted_portfolio(simple_returns)\n",
        "\n",
        "# Calculate portfolio statistics\n",
        "port_mean = portfolio_rets.mean() * 252\n",
        "port_std = portfolio_rets.std() * np.sqrt(252)\n",
        "port_sharpe = (port_mean - 0.02) / port_std\n",
        "\n",
        "print(f\"Portfolio Statistics:\")\n",
        "print(f\"Annual Return: {port_mean:.2%}\")\n",
        "print(f\"Annual Volatility: {port_std:.2%}\")  \n",
        "print(f\"Sharpe Ratio: {port_sharpe:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions - Part 3**\n",
        "\n",
        "7. What is the correlation between AAPL and JNJ? Is this good or bad for diversification?\n",
        "8. How does the portfolio's risk compare to the average risk of AAPL and JNJ individually?\n",
        "9. Calculate the \"diversification benefit\": (Average individual volatility) - (Portfolio volatility)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Your Answers - Part 3:**\n",
        "\n",
        "7. The correlation between AAPL and JNJ is .2396, this is okay for diversification since the correlation is a moderate positive number, and much less than 1.0. Combining these assests mean when AAPL's returns are low, JNJ's returns are not guaranteed to be low as well, which reduces the overall risk of the combined portfolio.\n",
        "\n",
        "8. The portfolio's risk is lower than the average risk of AAPL and JNJ individually. The average individual volaitility is (.2780 + .1619) / 2 = .2200, while the portfolio's risk is .1768.\n",
        "\n",
        "9. The diversification benefits is .2200 - .1768 = .0432."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 4: Market Relationships (Beta Analysis) (15 points)**\n",
        "\n",
        "### **Step 4.1: Beta Calculation**\n",
        "Calculate beta using the regression approach from the slides:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_beta(stock_returns, market_returns):\n",
        "    \"\"\"\n",
        "    Calculate beta using linear regression.\n",
        "    \n",
        "    Beta = Covariance(Stock, Market) / Variance(Market)\n",
        "    \"\"\"\n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Method 1: Using the covariance formula\n",
        "    # Method 2: Using sklearn.LinearRegression\n",
        "    # Compare both results\n",
        "    ######################\n",
        "    df = pd.DataFrame({'stock': stock_returns, 'market': market_returns}).dropna()\n",
        "    stock_returns = df['stock']\n",
        "    market_returns = df['market']\n",
        "    \n",
        "    beta_formula = stock_returns.cov(market_returns) / market_returns.var()\n",
        "\n",
        "    X = market_returns.values.reshape(-1, 1)\n",
        "    y = stock_returns.values\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    beta_regression = model.coef_[0]\n",
        "    print(f\"Method 1 (Covariance Formula): {beta_formula:.6f}\")\n",
        "    print(f\"Method 2 (Linear Regression Slope): {beta_regression:.6f}\")\n",
        "    return beta_formula\n",
        "\n",
        "# Calculate betas for AAPL and JNJ vs SPY\n",
        "aapl_beta = calculate_beta(simple_returns['AAPL'], simple_returns['SPY'])\n",
        "jnj_beta = calculate_beta(simple_returns['JNJ'], simple_returns['SPY'])\n",
        "\n",
        "print(f\"AAPL Beta: {aapl_beta:.3f}\")\n",
        "print(f\"JNJ Beta: {jnj_beta:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 4.2: Beta Visualization**\n",
        "Create scatter plots showing the relationship between stock and market returns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_beta_relationship(stock_returns, market_returns, stock_name, beta):\n",
        "    \"\"\"\n",
        "    Create scatter plot of stock vs market returns with regression line.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Create scatter plot of stock returns vs market returns\n",
        "    # Add regression line \n",
        "    # Include beta value in title\n",
        "    # Add proper axis labels\n",
        "    ######################\n",
        "\n",
        "    df = pd.DataFrame({'stock': stock_returns, 'market': market_returns}).dropna()\n",
        "    stock_returns = df['stock']\n",
        "    market_returns = df['market']\n",
        "\n",
        "    m, b = np.polyfit(market_returns, stock_returns, 1) \n",
        "\n",
        "    plt.scatter(market_returns, stock_returns, alpha=0.6, color='#1f77b4', label='Daily Returns')\n",
        "\n",
        "    plt.plot(market_returns, m * market_returns + b, color='red', \n",
        "             linewidth=2.5, label=f'Regression Line (Beta = {beta:.3f})') \n",
        "    \n",
        "    plt.title(f'{stock_name} vs Market (SPY) Returns | Beta: {beta:.3f}', fontsize=16)\n",
        "    plt.xlabel('Market Returns (SPY)', fontsize=12)\n",
        "    plt.ylabel(f'{stock_name} Returns', fontsize=12)\n",
        "    \n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Create plots for both stocks\n",
        "plot_beta_relationship(simple_returns['AAPL'], simple_returns['SPY'], 'AAPL', aapl_beta)\n",
        "plot_beta_relationship(simple_returns['JNJ'], simple_returns['SPY'], 'JNJ', jnj_beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions - Part 4**\n",
        "\n",
        "10. Which stock is more sensitive to market movements? How do you know?\n",
        "11. Based on beta, which stock would you expect to fall more in a market crash?\n",
        "12. Do the betas make intuitive sense given what you know about these companies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Your Answers - Part 4:**\n",
        "\n",
        "10. AAPL is more senstive to market movement. Beta measures the sensitivity of the stock's returns to the market's returns. A beta higher than 1 means the stock is more volatile than the stock market, and a beta lower than 1 means the stock is less volatile to market movement. Since AAPL's beta is higher than JNJ's beta it is more sensitive to market movements.\n",
        "\n",
        "11. I would expect AAPL to fall if the market crash, since its beta is higher, and thus has a higher tendency to follow market movement.\n",
        "\n",
        "12. Yes, the betas make intuitive sense since AAPL is a technology, consumer based company, which is dependent on consumer confidence. If the market is doing well, and consumers have high confidence they are more likely to buy AAPL products, whereas with JNJ a large pharma company, the demand for their products aren't as dependent on economic prosperity. People will still medicine and hospitals will still operate even if the economy is doing bad, so their stock isn't as effected. But it is still a little effected because if the current situation is bad enough, people will start forgoing their medication or doctors visits, explaining why the beta is not negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 5: Time Series Analysis (15 points)**\n",
        "\n",
        "### **Step 5.1: Cumulative Returns**\n",
        "Calculate and plot cumulative returns to show total performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_cumulative_returns(returns_df):\n",
        "    \"\"\"\n",
        "    Calculate and plot cumulative returns over time.\n",
        "    \"\"\"\n",
        "    # Calculate cumulative returns (compound growth)\n",
        "    cum_returns = (1 + returns_df).cumprod()\n",
        "    \n",
        "    # Plot cumulative returns\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Plot cumulative returns for all three assets\n",
        "    cum_returns.plot(ax=plt.gca(), linewidth=2.5)\n",
        "    final_returns = cum_returns.iloc[-1]\n",
        "    best_asset = final_returns.idxmax()\n",
        "    \n",
        "    # Add legend, title, and axis labels\n",
        "    plt.title('Cumulative Returns Comparison Over Time', fontsize=16)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Cumulative Growth of \\$1 Investment', fontsize=12)\n",
        "    # Show which investment performed best over time\n",
        "    plt.text(\n",
        "        x=cum_returns.index[0], \n",
        "        y=final_returns.max() * 0.95, # Place annotation near the top-left\n",
        "        s=f'Best Performer: {best_asset}', \n",
        "        fontsize=14, \n",
        "        color='green',\n",
        "        fontweight='bold'\n",
        "    )\n",
        "    plt.legend(title='Asset', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    ######################\n",
        "    plt.show()\n",
        "    \n",
        "    return cum_returns\n",
        "\n",
        "cumulative_returns = analyze_cumulative_returns(simple_returns)\n",
        "\n",
        "# Calculate total returns over the period\n",
        "total_returns = cumulative_returns.iloc[-1] - 1\n",
        "print(\"Total Returns over the period:\")\n",
        "for asset in total_returns.index:\n",
        "    print(f\"{asset}: {total_returns[asset]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 5.2: Rolling Statistics**\n",
        "Calculate rolling volatility to see how risk changes over time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_rolling_volatility(returns_df, window=60):\n",
        "    \"\"\"\n",
        "    Plot 60-day rolling volatility for all assets.\n",
        "    \"\"\"\n",
        "    # Calculate rolling standard deviation\n",
        "    rolling_vol = returns_df.rolling(window=window).std() * np.sqrt(252)\n",
        "\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    ######################\n",
        "    # YOUR CODE HERE\n",
        "    # Plot rolling volatility for all assets\n",
        "    rolling_vol.plot(ax=plt.gca(), linewidth=2)\n",
        "    # Add title indicating the window size\n",
        "    plt.title(f'Annualized Rolling Volatility ({window}-Day Window)', fontsize=16)\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Annualized Volatility (Standard Deviation)', fontsize=12)\n",
        "    plt.legend(title='Asset', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    ######################\n",
        "    plt.show()\n",
        "\n",
        "plot_rolling_volatility(simple_returns, window=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Questions - Part 5**\n",
        "\n",
        "13. Which asset had the best total return? Was this expected based on risk levels?\n",
        "14. During which time periods was volatility highest? Can you guess why?\n",
        "15. How does rolling volatility help us understand changing market conditions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Your Answers - Part 5:**\n",
        "\n",
        "13. AAPL had the best total return. That makes sense since it had the highest risk, and the highest sharpe ratio.\n",
        "\n",
        "14. The periods of highest volatility were May 2022 - March 2023, this was likely due to some current events. Start of May, Russia was defaulting on their debt, sactions were placed on Russian businesses, which might have effected consumer confidence. Furthermore, the volatility was calculated with SPY, AAPL, and JNJ, during this time AAPL was accused of violating the EU compeition law, which must have servely effected their stock.\n",
        "\n",
        "15. Rolling volatility helps us understand risk levels, since volatility is a marker for risk. Low volatility means market is complacent, steady growth, in a bull market, whereas high volatility indicated uncertantity and sharp price movement. When markets shift, it is marked with increased volatility, showing how the enviornment has changed, which could result in a change of strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Part 6: Summary Analysis and Interpretation (10 points)**\n",
        "\n",
        "Write a brief analysis (300-500 words) answering these questions:\n",
        "\n",
        "### **Investment Summary**\n",
        "Based on your analysis, write responses to these prompts:\n",
        "\n",
        "1. **Risk-Return Profile**: Summarize the risk and return characteristics of each asset. Which offered the best risk-adjusted returns?\n",
        "\n",
        "2. **Diversification Benefits**: Explain whether combining AAPL and JNJ in a portfolio provided diversification benefits. Use specific numbers from your analysis.\n",
        "\n",
        "3. **Market Sensitivity**: Compare how AAPL and JNJ respond to market movements using your beta analysis. What does this mean for an investor?\n",
        "\n",
        "4. **Time-Varying Risk**: Describe how volatility changed over your sample period. What events might explain these changes?\n",
        "\n",
        "5. **Investment Recommendation**: If you had to choose between investing in individual stocks or the diversified portfolio, what would you recommend and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **My Analysis**\n",
        "\n",
        "### **My Analysis**\n",
        "\n",
        "1. AAPL offered the highest annualized return (17.76%) but also the highest annualized volatility (0.2780). Its daily mean return was 0.0007. JNJ had the lowest annualized return (4.06%) and the lowest annualized volatility (0.1619). Its daily mean return was 0.0002. Finally, SPY fell in the middle with an annualized return of 11.54% and volatility of 0.1760. Its daily mean return was 0.0005. Knowing all these stats, the best risk-adjusted return was offered by AAPL, corroborated by its sharpe ratio of 0.5668 (the highest of all three equitites). This means AAPL provides the greatest return per unit of risk.\n",
        "\n",
        "2. Combining AAPL and JNJ provide diversification benefits, which only happen when the equitites in question are not perfectly correlated, reducing total portfolio volatility. The correlation between AAPL and JNJ is 0.2396. Since this correlation is significantly less than +1.0, the portfolio's overall volatility will be lower than the weighted average of the individual volatilities. A correlation of 0.2396 indicates a weak positive relationship, which is beneficial for reducing portfolio risk. \n",
        "\n",
        "3. Beta measures an assest's sensitvity to market movement. AAPL Beta is 1.272, which means AAPL is an aggressive stock that is more sensitive to market movements than the average stock. A 1% increase in the market return is associated with a 1.272% increase in AAPL's return. JNJ Beta is 0.326 which means JNJ is a defensive stock that is less sensitive to market movements than the average stock. A 1% increase in the market return is associated with only a 0.326% increase in JNJ's return. For an investor this analysis would provide insight on how they pick stocks for their portfolio. If an investor is seeking higher growth and is willing to take on more systemic risk they would find AAPL attractive. Whereas if an investor seeking stability and lower systemic risk would prefer JNJ. JNJ's returns are less affected by broad market swings, making it a good \"buffer\" stock for a diversified portfolio, especially during market corrections.\n",
        "\n",
        "4. Looking at the rolling volatility chart, the period of high volatility was May 2022 - March 2023. Here the volatility rose above .35, and the volatility itself was somewhat volatile, which could be intersting for people trading volatility swaps or other derivatives which look at volatility on volatility. But, this was likely due to some current events. Start of May, Russia was defaulting on their debt, sactions were placed on Russian businesses, which might have effected consumer confidence. Furthermore, the volatility was calculated with SPY, AAPL, and JNJ, during this time AAPL was accused of violating the EU compeition law, which must have servely effected their stock.\n",
        "\n",
        "\n",
        "5. I would recommend a diversifed portfolio over investing in an individual stock. Since we know the sharpe ratios of AAPL (0.504), JNJ (0.5668), and SPY (0.1274), depending on the risk tolerance and growth goals of the client, AAPL would be a nice pick for a decent weighting of the portfolio because it has the highest sharpe ratio. However, AAPL also had the highest beta, so the porfolio should account for this, with a similar weighting of JNJ, to ensure the porfolio is hedged on beta. If the stock market is not doing as well, JNJ won't be as affected as AAPL would be. Furthermore, since AAPL and JNJ have a lower correlation, the portfolio would have diversification benefits, reducing the overall risk. SPY would offer board market exposure, and decent diversitifcation in itself since it is an ETF, so it would should also have a decent position in the portfolio. I would say 35% JNJ, 25% AAPL, and 40% SPY.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Bonus Section: Probability Application (5 extra points)**\n",
        "\n",
        "Apply probability concepts from Week 1 slides:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_portfolio_outcomes(returns_df, num_simulations=1000, time_horizon=252):\n",
        "    \"\"\"\n",
        "    Use Monte Carlo simulation to project potential portfolio outcomes.\n",
        "    Assume returns follow a normal distribution.\n",
        "    Also assume the stock price follows a geometric Brownian motion.\n",
        "    \"\"\"\n",
        "    weights = np.array([0.45, 0.10, 0.45])\n",
        "\n",
        "    returns = returns_df.dropna().copy()\n",
        "\n",
        "    returns['Portfolio_Returns'] = returns.dot(weights)\n",
        "\n",
        "    mu_d = returns['Portfolio_Returns'].mean()\n",
        "    sigma_d = returns['Portfolio_Returns'].std()\n",
        "\n",
        "    final_values = np.zeros(num_simulations)\n",
        "\n",
        "    P0 = 1.0\n",
        "\n",
        "    drift = mu_d - 0.5 * sigma_d**2\n",
        "    volatility_term = sigma_d\n",
        "\n",
        "    for i in range(num_simulations):\n",
        "        # Generate T random draws from a standard normal distribution (Z)\n",
        "        daily_shocks = np.random.normal(0, 1, time_horizon)\n",
        "        \n",
        "        # Calculate daily return factors for the path (Geometric Brownian Motion)\n",
        "        daily_returns_factor = np.exp(drift + volatility_term * daily_shocks)\n",
        "        \n",
        "        # Calculate the cumulative product of daily returns to get the final value\n",
        "        final_value = P0 * np.prod(daily_returns_factor)\n",
        "        \n",
        "        # Store the result\n",
        "        final_values[i] = final_value\n",
        "\n",
        "    final_returns_percent = (final_values - 1.0) * 100\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(final_returns_percent, bins=50, edgecolor='k', alpha=0.7)\n",
        "    plt.title(f'Monte Carlo Simulation of Portfolio Returns Over {time_horizon} Days (Weights: {weights})')\n",
        "    plt.xlabel('Final Portfolio Return (%)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.axvline(x=0, color='r', linestyle='--', label='Breakeven (0% Return)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    probability_of_loss = np.sum(final_values < P0) / num_simulations\n",
        "    \n",
        "    # Print Summary Statistics\n",
        "    print(\"\\n--- Simulation Summary ---\")\n",
        "    print(f\"Number of Simulations: {num_simulations}\")\n",
        "    print(f\"Time Horizon: {time_horizon} trading days (approx. 1 year)\")\n",
        "    print(f\"Daily Mean Return (mu_d): {mu_d:.4f}\")\n",
        "    print(f\"Daily Standard Deviation (sigma_d): {sigma_d:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Mean Final Return: {np.mean(final_returns_percent):.2f}%\")\n",
        "    print(f\"Median Final Return: {np.median(final_returns_percent):.2f}%\")\n",
        "    print(f\"95% Confidence Interval (VaR): [{np.percentile(final_returns_percent, 2.5):.2f}%, {np.percentile(final_returns_percent, 97.5):.2f}%]\")\n",
        "    print(f\"\\nProbability of Losing Money (Return < 0%): {probability_of_loss * 100:.2f}%\")\n",
        "\n",
        "\n",
        "    ######################\n",
        "\n",
        "# Run simulation\n",
        "simulate_portfolio_outcomes(simple_returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## **Submission Checklist**\n",
        "\n",
        "Before submitting, make sure you have:\n",
        "\n",
        "- [ ] Filled in your name and GT username at the top\n",
        "- [ ] Completed all code sections with working implementations\n",
        "- [ ] Answered all 15 numbered questions in the markdown cells\n",
        "- [ ] Written the 300-500 word summary analysis\n",
        "- [ ] All code cells run without errors\n",
        "- [ ] All plots display correctly\n",
        "- [ ] Saved the notebook as `quant_intro_project_[GTUsername].ipynb`\n",
        "- [ ] Exported a PDF version showing all outputs\n",
        "- [ ] Push your code to your personal Git repo\n",
        "\n",
        "**Good luck!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
